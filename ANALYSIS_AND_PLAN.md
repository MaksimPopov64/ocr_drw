# Анализ приложения OCR и План Рефакторинга

## 1. Обнаруженные Проблемы

### Критические ошибки в коде
1. **Несоответствие имен классов**:
   - В файле `app.py` происходит импорт: `from mistral_processor import MistralOCRProcessor`.
   - Однако в файле `mistral_processor.py` класс называется `EnhancedMistralOCRProcessor`.
   - **Результат**: Приложение упадет с ошибкой `ImportError` при запуске.

2. **Отсутствующие зависимости**:
   - Файл `ocr_processor.py` использует библиотеку `easyocr`, но она отсутствует в `requirements.txt`.

### Проблемы качества OCR (по предоставленному примеру)
1. **Не находится "Акт по заявке №"**:
   - Текущий регулярный шаблон: `r"заявк[еи]\s*№?\s*(\d+)"`.
   - Проблема: Он слишком строг к символу номера. Если OCR распознает "№" как "N", "No" или просто пропустит его (оставив пробел), регулярное выражение не сработает. Также оно ожидает, что слово "заявке" будет распознано идеально.
   - В примере на изображении текст "по заявке № 2237968". Если OCR ошибется хотя бы в одной букве (например "заявк**а**"), шаблон может не сработать (хотя `[еи]` там есть, `а` нет).

2. **Плохое распознавание таблицы "Выполненные работы"**:
   - Текущий подход использует LLaVA 7b с промптом "Extract ALL visible text...".
   - **Проблема**: LLaVA 7b (особенно старые версии) плохо справляется с сохранением сложной табличной структуры и связей "строка-значение" в плотном русском тексте. Она часто смешивает столбцы или галлюцинирует текст при попытке восстановить структуру.
   - **Предобработка**: Метод `advanced_preprocess_image` использует жесткую бинаризацию и шумоподавление. Это может "съедать" тонкие шрифты или делать текст неразборчивым для нейросетей, которые обучены на обычных фото/сканах (RGB).

---

## 2. План Рефакторинга

### Шаг 1: Исправление кода
1. Переименовать класс в `app.py` или `mistral_processor.py` для согласованности.
2. Добавить `easyocr` (и `torch` при необходимости) в `requirements.txt` или удалить `ocr_processor.py`, если он не используется (судя по `app.py`, используется только `mistral_processor`).

### Шаг 2: Улучшение логики поиска (Regex)
Обновить паттерны поиска номера заявки, сделав их более "всеядными":
```python
extraction_patterns = {
    "claim_number": [
        r"заявк\w*\s*(?:№|N|No|#)?\s*(\d{5,})",  # Гибкий поиск после слова заявка
        r"(?:№|N|No|#)\s*(\d{6,})",             # Поиск по знаку номера и длинному числу
        r"АКТ.*?(\d{6,})"                       # Контекстный поиск
    ],
    # ...
}
```

### Шаг 3: Оптимизация Предобработки
Сделать предобработку менее агрессивной для LLaVA:
- Отключить бинаризацию и сильное размытие для нейросетевого входа. Оставить их только для Tesseract.
- Для LLaVA лучше подавать оригинальное (или слегка скорректированное по контрасту) RGB изображение.

### Шаг 4: Интеграция EasyOCR (как второго слоя)
Использовать `EasyOCR` не как альтернативу, а как валидатор для номеров, так как он часто лучше читает цифры и "пиксельные" шрифты, чем LLM.

---

## 3. Рекомендации по замене LLM (Mistral/LLaVA)

Текущий стек (`mistral:7b` + `llava:7b`) устарел и не оптимален для OCR на русском языке.

### Рекомендуемая замена для Vision (OCR)
1. **Qwen2.5-VL (7B)**:
   - **Почему**: На данный момент (2025) это одна из лучших opensource моделей для Vision. Она отлично понимает документы, таблицы и русский язык. Работает намного точнее LLaVA 1.5/1.6.
   - **Доступность**: Поддерживается в Ollama и vLLM.

2. **Llama-3.2-Vision (11B или 90B)**:
   - **Почему**: Сильная модель от Meta, хорошо следует инструкциям по извлечению JSON.
   - **Минус**: Может быть тяжеловата для локального запуска (требует больше VRAM).

3. **Mini-CPM-V-2.6**:
   - **Почему**: Очень легкая (8B), но специализируется на OCR высокого разрешения. Часто превосходит GPT-4V на тестах OCR. Идеальна для запуска на consumer-hardware.

### Рекомендуемая замена для Text Correction / Logic
1. **Qwen2.5-7B-Instruct**:
   - **Почему**: Значительно умнее Mistral 7b v0.2. Лучше работает с русским языком, лучше следует формату JSON, меньше галлюцинирует.

### Итоговая конфигурация (для локального запуска)
- **Vision Model**: `Qwen2.5-VL-7B` (или `MiniCPM-V` если ресурсы ограничены).
- **Processing Logic**: Промпт должен требовать **JSON**, а не просто текст.

**Пример улучшенного промпта:**
```text
System: You are an expert document parser.
User: Analyze this image of a Service Act. Extract data into VALID JSON format with these exact keys:
{
  "claim_number": "string or null",
  "client_name": "string or null",
  "service_table": [
      {"item_name": "string", "quantity": "number"}
  ],
  "total_sum": "string"
}
Look carefully for "Заявка №" or similar. For the table, extract strictly line by line.
```
